{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"prev_pub_hash":"6ba5708670eb874d11b1986f618eaa8799647f83c72a160040774db4b8643fab","kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Collaborative Filtering based Recommender System using Non-negative Matrix Factorization**\n","metadata":{}},{"cell_type":"markdown","source":"In the previous notebook, we have performed KNN on user-item interaction matrix to estimate the rating of unknown items based on the aggregation of the user's K nearest neighbor's ratings. Finding nearest neighbors are based on similarity measurements among users or items with big similarity matrices. \n","metadata":{}},{"cell_type":"markdown","source":"The KNN algorithm is memory-based which means we need to keep all instances for prediction and maintain a big similarity matrix. These can be infeasible if our user/item scale is large, for example, 1 million users will require a 1 million by 1 million similarity matrix, which is very hard to load into RAM for most computation environments.\n","metadata":{}},{"cell_type":"markdown","source":"#### Non-negative matrix factorization\n","metadata":{}},{"cell_type":"markdown","source":"In the machine learning course, you have learned a dimensionality reduction algorithm called Non-negative matrix factorization (NMF), which decomposes a big sparse matrix into two smaller and dense matrices.\n\nNon-negative matrix factorization can be one solution to big matrix issues. The main idea is to decompose the big and sparse user-interaction into two smaller dense matrices, one represents the transformed user features and another represents the transformed item features.\n","metadata":{}},{"cell_type":"markdown","source":"An example is shown below, suppose we have a user-item interaction matrix $A$ with 10000 users and 100 items (10000 x 100), and its element `(j, k)` represents the rating of item `k` from user `j`. Then we could decompose $A$ into two smaller and dense matrices $U$ (10000 x 16) and $I$ (16 x 100). for user matrix $U$, each row vector is a transformed latent feature vector of a user, and for the item matrix $I$, each column is a transformed latent feature vector of an item. \n\nHere the dimension 16 is a hyperparameter defines the size of the hidden user and item features, which means now the shape of transposed user feature vector and item feature vector is now 16 x 1.\n","metadata":{}},{"cell_type":"markdown","source":"The magic here is when we multiply the row `j` of $U$ and column `k` of matrix $I$, we can get an estimation to the original rating $\\hat{r}_{jk}$. \n\nFor example, if we preform the dot product user ones  row vector in $U$ and item ones  column vector in $I$, we can get the rating estimation of user one to item one, which is the element (1, 1) in the original interaction matrix $I$. \n","metadata":{}},{"cell_type":"markdown","source":"![](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-ML321EN-SkillsNetwork/labs/module_4/images/nmf.png)\n","metadata":{}},{"cell_type":"markdown","source":"Note $I$ is short for Items, and it is not an identity matrix.\n","metadata":{}},{"cell_type":"markdown","source":"Then how do we figure out the values in $U$ and $I$ exactly? Like many other machine learning processes, we could start by initializing the values of $U$ and $I$, then define the following distance or cost function to be minimized:\n","metadata":{}},{"cell_type":"markdown","source":"$$\\sum_{r_{jk} \\in {train}} \\left(r_{jk} - \\hat{r}_{jk} \\right)^2,$$\n","metadata":{}},{"cell_type":"markdown","source":"where $\\hat{r}_{ij}$ is the dot product of $u_j^T$ and $i_k$:\n","metadata":{}},{"cell_type":"markdown","source":"$$\\hat{r}_{jk} = u_j^Ti_k$$\n","metadata":{}},{"cell_type":"markdown","source":"The cost function can be optimized using stochastic gradient descent (SGD) or other optimization algorithms, just like in training the weights in a logistic regression model (there are several additional steps so the matrices have no negative elements) . \n","metadata":{}},{"cell_type":"markdown","source":"## Objectives\n","metadata":{}},{"cell_type":"markdown","source":"* Perform NMF-based collaborative filtering on the user-item matrix\n","metadata":{}},{"cell_type":"markdown","source":"----\n","metadata":{}},{"cell_type":"markdown","source":"### Load and exploring dataset\n","metadata":{}},{"cell_type":"markdown","source":"Let's first load our dataset, i.e., the user-item (learn-course) interaction matrix\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-06-18T17:51:43.394292Z","iopub.execute_input":"2024-06-18T17:51:43.394853Z","iopub.status.idle":"2024-06-18T17:51:43.841355Z","shell.execute_reply.started":"2024-06-18T17:51:43.394813Z","shell.execute_reply":"2024-06-18T17:51:43.840352Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"rating_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMSkillsNetwork-ML0321EN-Coursera/labs/v2/module_3/ratings.csv\"\nrating_df = pd.read_csv(rating_url)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T17:51:43.843542Z","iopub.execute_input":"2024-06-18T17:51:43.843987Z","iopub.status.idle":"2024-06-18T17:51:45.115217Z","shell.execute_reply.started":"2024-06-18T17:51:43.843959Z","shell.execute_reply":"2024-06-18T17:51:45.114255Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"rating_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-18T17:51:45.116471Z","iopub.execute_input":"2024-06-18T17:51:45.116766Z","iopub.status.idle":"2024-06-18T17:51:45.131553Z","shell.execute_reply.started":"2024-06-18T17:51:45.116741Z","shell.execute_reply":"2024-06-18T17:51:45.130448Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"      user        item  rating\n0  1889878    CC0101EN       5\n1  1342067    CL0101EN       3\n2  1990814  ML0120ENv3       5\n3   380098    BD0211EN       5\n4   779563    DS0101EN       3","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>item</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1889878</td>\n      <td>CC0101EN</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1342067</td>\n      <td>CL0101EN</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1990814</td>\n      <td>ML0120ENv3</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>380098</td>\n      <td>BD0211EN</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>779563</td>\n      <td>DS0101EN</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"The dataset contains three columns, `user id`, `item id`, and `the rating`. Note that this matrix is presented as the dense or vertical form, you may convert it using `pivot` to the original sparse matrix:\n","metadata":{}},{"cell_type":"code","source":"rating_sparse_df = rating_df.pivot(index='user', columns='item', values='rating').fillna(0).reset_index().rename_axis(index=None, columns=None)\nrating_sparse_df.head()","metadata":{"execution":{"iopub.status.busy":"2024-06-18T17:51:45.134585Z","iopub.execute_input":"2024-06-18T17:51:45.134909Z","iopub.status.idle":"2024-06-18T17:51:45.373414Z","shell.execute_reply.started":"2024-06-18T17:51:45.134882Z","shell.execute_reply":"2024-06-18T17:51:45.372319Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   user  AI0111EN  BC0101EN  BC0201EN  BC0202EN  BD0101EN  BD0111EN  BD0115EN  \\\n0     2       0.0       4.0       0.0       0.0       5.0       4.0       0.0   \n1     4       0.0       0.0       0.0       0.0       5.0       3.0       4.0   \n2     5       3.0       5.0       5.0       0.0       4.0       0.0       0.0   \n3     7       0.0       0.0       0.0       0.0       0.0       0.0       0.0   \n4     8       0.0       0.0       0.0       0.0       0.0       3.0       0.0   \n\n   BD0121EN  BD0123EN  ...  SW0201EN  TA0105  TA0105EN  TA0106EN  TMP0101EN  \\\n0       5.0       3.0  ...       0.0     5.0       0.0       4.0        0.0   \n1       5.0       3.0  ...       0.0     4.0       0.0       0.0        0.0   \n2       0.0       3.0  ...       0.0     0.0       4.0       4.0        4.0   \n3       0.0       0.0  ...       0.0     0.0       0.0       0.0        0.0   \n4       0.0       0.0  ...       0.0     0.0       0.0       0.0        0.0   \n\n   TMP0105EN  TMP0106  TMP107  WA0101EN  WA0103EN  \n0        3.0      3.0     0.0       5.0       0.0  \n1        3.0      3.0     0.0       3.0       3.0  \n2        4.0      4.0     5.0       0.0       3.0  \n3        0.0      0.0     0.0       0.0       0.0  \n4        0.0      0.0     0.0       0.0       0.0  \n\n[5 rows x 127 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>user</th>\n      <th>AI0111EN</th>\n      <th>BC0101EN</th>\n      <th>BC0201EN</th>\n      <th>BC0202EN</th>\n      <th>BD0101EN</th>\n      <th>BD0111EN</th>\n      <th>BD0115EN</th>\n      <th>BD0121EN</th>\n      <th>BD0123EN</th>\n      <th>...</th>\n      <th>SW0201EN</th>\n      <th>TA0105</th>\n      <th>TA0105EN</th>\n      <th>TA0106EN</th>\n      <th>TMP0101EN</th>\n      <th>TMP0105EN</th>\n      <th>TMP0106</th>\n      <th>TMP107</th>\n      <th>WA0101EN</th>\n      <th>WA0103EN</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 127 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Next, you need to implement NMF-based collaborative filtering, and you may choose one of the two following implementation options: \n- The first one is to use `Surprise` which is a popular and easy-to-use Python recommendation system library. \n- The second way is to implement it with `numpy`, `pandas`, and `sklearn`. You may need to write a lot of low-level implementation code along the way.\n","metadata":{}},{"cell_type":"markdown","source":"## Implementation Option 1: Use **Surprise** library (recommended)\n","metadata":{}},{"cell_type":"markdown","source":"*Surprise* is a Python scikit library for recommender systems. It is simple and comprehensive to build and test different recommendation algorithms. First let's install it:\n","metadata":{}},{"cell_type":"code","source":"!pip install scikit-surprise","metadata":{"execution":{"iopub.status.busy":"2024-06-18T17:51:45.374872Z","iopub.execute_input":"2024-06-18T17:51:45.375286Z","iopub.status.idle":"2024-06-18T17:52:01.133448Z","shell.execute_reply.started":"2024-06-18T17:51:45.375248Z","shell.execute_reply":"2024-06-18T17:52:01.132139Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: scikit-surprise in /opt/conda/lib/python3.10/site-packages (1.1.4)\nRequirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from scikit-surprise) (1.4.2)\nRequirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.10/site-packages (from scikit-surprise) (1.26.4)\nRequirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from scikit-surprise) (1.11.4)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We import required classes and methods\n","metadata":{}},{"cell_type":"code","source":"from surprise import NMF\nfrom surprise import Dataset, Reader\nfrom surprise.model_selection import train_test_split\nfrom surprise import accuracy","metadata":{"execution":{"iopub.status.busy":"2024-06-18T17:52:01.135135Z","iopub.execute_input":"2024-06-18T17:52:01.135542Z","iopub.status.idle":"2024-06-18T17:52:01.180510Z","shell.execute_reply.started":"2024-06-18T17:52:01.135508Z","shell.execute_reply":"2024-06-18T17:52:01.179447Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Save the rating dataframe to a CSV file\nrating_df.to_csv(\"course_ratings.csv\", index=False)\n\n# Read the course rating dataset with columns user item rating\nreader = Reader(line_format='user item rating', sep=',', skip_lines=1, rating_scale=(2, 3))\n\n# Load the dataset from the CSV file\ncourse_dataset = Dataset.load_from_file(\"course_ratings.csv\", reader=reader)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T17:52:01.181876Z","iopub.execute_input":"2024-06-18T17:52:01.182473Z","iopub.status.idle":"2024-06-18T17:52:02.296044Z","shell.execute_reply.started":"2024-06-18T17:52:01.182442Z","shell.execute_reply":"2024-06-18T17:52:02.294708Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Now  we split the data into a train-set and test-set:\n","metadata":{}},{"cell_type":"code","source":"trainset, testset = train_test_split(course_dataset, test_size=.3)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T17:52:02.297397Z","iopub.execute_input":"2024-06-18T17:52:02.297762Z","iopub.status.idle":"2024-06-18T17:52:02.866740Z","shell.execute_reply.started":"2024-06-18T17:52:02.297733Z","shell.execute_reply":"2024-06-18T17:52:02.865461Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Then check how many users and items we can use to fit the KNN model:\n","metadata":{}},{"cell_type":"code","source":"print(f\"Total {trainset.n_users} users and {trainset.n_items} items in the trainingset\")","metadata":{"execution":{"iopub.status.busy":"2024-06-18T17:52:02.868606Z","iopub.execute_input":"2024-06-18T17:52:02.869002Z","iopub.status.idle":"2024-06-18T17:52:02.874342Z","shell.execute_reply.started":"2024-06-18T17:52:02.868963Z","shell.execute_reply":"2024-06-18T17:52:02.873374Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Total 31377 users and 126 items in the trainingset\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Perform NMF-based collaborative filtering on the course-interaction matrix\n","metadata":{}},{"cell_type":"markdown","source":"Fit a NMF model using the trainset and evaluate the results using the testset_ The code will be very similar to the KNN-based collaborative filtering, we just need to use the `NMF()` model.\n","metadata":{}},{"cell_type":"code","source":"# We'll use the famous SVD algorithm.\nalgo = NMF()\n\n# Train the algorithm on the trainset, and predict ratings for the testset\nalgo.fit(trainset)\npredictions = algo.test(testset)\n\n# Then compute RMSE\naccuracy.rmse(predictions)","metadata":{"execution":{"iopub.status.busy":"2024-06-18T17:52:02.878135Z","iopub.execute_input":"2024-06-18T17:52:02.878559Z","iopub.status.idle":"2024-06-18T17:52:13.444874Z","shell.execute_reply.started":"2024-06-18T17:52:02.878522Z","shell.execute_reply":"2024-06-18T17:52:13.443732Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"RMSE: 1.3094\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"1.309409658034098"},"metadata":{}}]},{"cell_type":"markdown","source":"To learn more detailed usages about _Surprise_ library, visit its website from [here](https://surprise.readthedocs.io/en/stable/getting_started.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML321ENSkillsNetwork817-2022-01-01)\n","metadata":{}},{"cell_type":"markdown","source":"## Implementation Option 2: Use `numpy`, `pandas`, and `sklearn`.\n","metadata":{}},{"cell_type":"markdown","source":"If you do not prefer the one-stop Suprise solution, you may implement the KNN model using `numpy`, `pandas`, and possibly `sklearn`:\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.decomposition import NMF\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt","metadata":{"execution":{"iopub.status.busy":"2024-06-18T17:52:13.446267Z","iopub.execute_input":"2024-06-18T17:52:13.446746Z","iopub.status.idle":"2024-06-18T17:52:14.084052Z","shell.execute_reply.started":"2024-06-18T17:52:13.446717Z","shell.execute_reply":"2024-06-18T17:52:14.083127Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"num_components = 2\nmodel = NMF(n_components=num_components, random_state=42)\n\n \nU = model.fit_transform(rating_sparse_df)   \nI = model.components_  ","metadata":{"execution":{"iopub.status.busy":"2024-06-18T17:52:14.085262Z","iopub.execute_input":"2024-06-18T17:52:14.085627Z","iopub.status.idle":"2024-06-18T17:52:14.479234Z","shell.execute_reply.started":"2024-06-18T17:52:14.085599Z","shell.execute_reply":"2024-06-18T17:52:14.477746Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"predicted_ratings = np.dot(U, I)  # U dot I(assuming item factors are along columns) \n#can also be done by matmul using the formula defined above as U * I^T\n\n# Flatten the actual and predicted ratings for RMSE calculation\nactual_ratings = rating_sparse_df.values.flatten()\npredicted_ratings = predicted_ratings.flatten()\n\n# Calculate RMSE\nrmse = sqrt(mean_squared_error(actual_ratings, predicted_ratings))\nprint(f\"RMSE: {rmse}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-18T17:52:14.481733Z","iopub.execute_input":"2024-06-18T17:52:14.482793Z","iopub.status.idle":"2024-06-18T17:52:14.638909Z","shell.execute_reply.started":"2024-06-18T17:52:14.482719Z","shell.execute_reply":"2024-06-18T17:52:14.637854Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"RMSE: 0.8627711315436797\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Summary\n","metadata":{}},{"cell_type":"markdown","source":"In this notebook, you have learned and practiced NMF-based collaborative filtering. The basic idea is to decompose the original user-item interaction matrix into two smaller and dense user and item matrices. Then, we have built the two matrices, we can easily estimate the unknown ratings via the dot product of specific row in user matrix and specific column in item matrix.\n","metadata":{}}]}